{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport plotly.express as px \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import euclidean_distances\nfrom scipy.spatial.distance import cdist\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-12-17T05:44:20.714397Z","iopub.execute_input":"2021-12-17T05:44:20.71533Z","iopub.status.idle":"2021-12-17T05:44:21.808185Z","shell.execute_reply.started":"2021-12-17T05:44:20.715276Z","shell.execute_reply":"2021-12-17T05:44:21.807394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Read Data**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/spotify-dataset/data/data.csv\")\ngenre_data = pd.read_csv('../input/spotify-dataset/data/data_by_genres.csv')\nyear_data = pd.read_csv('../input/spotify-dataset/data/data_by_year.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T05:44:21.809689Z","iopub.execute_input":"2021-12-17T05:44:21.810083Z","iopub.status.idle":"2021-12-17T05:44:22.522129Z","shell.execute_reply.started":"2021-12-17T05:44:21.810053Z","shell.execute_reply":"2021-12-17T05:44:22.521334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.info())","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:22.523285Z","iopub.execute_input":"2021-12-17T05:44:22.523745Z","iopub.status.idle":"2021-12-17T05:44:22.617801Z","shell.execute_reply.started":"2021-12-17T05:44:22.523696Z","shell.execute_reply":"2021-12-17T05:44:22.616916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(genre_data.info())","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:22.62063Z","iopub.execute_input":"2021-12-17T05:44:22.621083Z","iopub.status.idle":"2021-12-17T05:44:22.634669Z","shell.execute_reply.started":"2021-12-17T05:44:22.621037Z","shell.execute_reply":"2021-12-17T05:44:22.63377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(year_data.info())","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:22.636084Z","iopub.execute_input":"2021-12-17T05:44:22.636733Z","iopub.status.idle":"2021-12-17T05:44:22.647925Z","shell.execute_reply.started":"2021-12-17T05:44:22.636686Z","shell.execute_reply":"2021-12-17T05:44:22.646858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from yellowbrick.target import FeatureCorrelation\n\nfeature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n       'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n\nX, y = data[feature_names], data['popularity']\n\n# Create a list of the feature names\nfeatures = np.array(feature_names)\n\n# Instantiate the visualizer\nvisualizer = FeatureCorrelation(labels=features)\n\nplt.rcParams['figure.figsize']=(20,20)\nvisualizer.fit(X, y)     # Fit the data to the visualizer\nvisualizer.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:22.649461Z","iopub.execute_input":"2021-12-17T05:44:22.650055Z","iopub.status.idle":"2021-12-17T05:44:22.923236Z","shell.execute_reply.started":"2021-12-17T05:44:22.650012Z","shell.execute_reply":"2021-12-17T05:44:22.922246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_decade(year):\n    period_start = int(year/10) * 10\n    decade = '{}s'.format(period_start)\n    return decade\n\ndata['decade'] = data['year'].apply(get_decade)\n\nsns.set(rc={'figure.figsize':(11 ,6)})\nsns.countplot(data['decade'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:23.523636Z","iopub.execute_input":"2021-12-17T05:44:23.524059Z","iopub.status.idle":"2021-12-17T05:44:23.989474Z","shell.execute_reply.started":"2021-12-17T05:44:23.524023Z","shell.execute_reply":"2021-12-17T05:44:23.988566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sound_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'valence']\nfig = px.line(year_data, x='year', y=sound_features)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:24.032665Z","iopub.execute_input":"2021-12-17T05:44:24.033039Z","iopub.status.idle":"2021-12-17T05:44:24.481812Z","shell.execute_reply.started":"2021-12-17T05:44:24.033003Z","shell.execute_reply":"2021-12-17T05:44:24.480785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top10_genres = genre_data.nlargest(10, 'popularity')\n\nfig = px.bar(top10_genres, x='genres', y=['valence', 'energy', 'danceability', 'acousticness'], barmode='group')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:24.975629Z","iopub.execute_input":"2021-12-17T05:44:24.976028Z","iopub.status.idle":"2021-12-17T05:44:25.069728Z","shell.execute_reply.started":"2021-12-17T05:44:24.975994Z","shell.execute_reply":"2021-12-17T05:44:25.06874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\ncluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=10, n_jobs=-1))])\nX = genre_data.select_dtypes(np.number)\ncluster_pipeline.fit(X)\ngenre_data['cluster'] = cluster_pipeline.predict(X)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T05:44:26.212124Z","iopub.execute_input":"2021-12-17T05:44:26.212698Z","iopub.status.idle":"2021-12-17T05:44:26.518808Z","shell.execute_reply.started":"2021-12-17T05:44:26.212632Z","shell.execute_reply":"2021-12-17T05:44:26.517759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the Clusters with t-SNE\n\nfrom sklearn.manifold import TSNE\n\ntsne_pipeline = Pipeline([('scaler', StandardScaler()), ('tsne', TSNE(n_components=2, verbose=1))])\ngenre_embedding = tsne_pipeline.fit_transform(X)\nprojection = pd.DataFrame(columns=['x', 'y'], data=genre_embedding)\nprojection['genres'] = genre_data['genres']\nprojection['cluster'] = genre_data['cluster']\n\nfig = px.scatter(\n    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'genres'])\nfig.show()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-12-17T05:44:27.518353Z","iopub.execute_input":"2021-12-17T05:44:27.518738Z","iopub.status.idle":"2021-12-17T05:44:43.188605Z","shell.execute_reply.started":"2021-12-17T05:44:27.518702Z","shell.execute_reply":"2021-12-17T05:44:43.187534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Clustering Songs with K-Means**","metadata":{}},{"cell_type":"code","source":"song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), \n                                  ('kmeans', KMeans(n_clusters=20, \n                                   verbose=False, n_jobs=4))\n                                 ], verbose=False)\n\nX = data.select_dtypes(np.number)\nnumber_cols = list(X.columns)\nsong_cluster_pipeline.fit(X)\nsong_cluster_labels = song_cluster_pipeline.predict(X)\ndata['cluster_label'] = song_cluster_labels","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-17T05:44:43.190695Z","iopub.execute_input":"2021-12-17T05:44:43.191246Z","iopub.status.idle":"2021-12-17T05:44:55.203359Z","shell.execute_reply.started":"2021-12-17T05:44:43.191203Z","shell.execute_reply":"2021-12-17T05:44:55.202178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the Clusters with PCA\n\nfrom sklearn.decomposition import PCA\n\npca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\nsong_embedding = pca_pipeline.fit_transform(X)\nprojection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\nprojection['title'] = data['name']\nprojection['cluster'] = data['cluster_label']\n\nfig = px.scatter(\n    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\nfig.show()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-12-17T05:44:55.204917Z","iopub.execute_input":"2021-12-17T05:44:55.205249Z","iopub.status.idle":"2021-12-17T05:45:01.491666Z","shell.execute_reply.started":"2021-12-17T05:44:55.205217Z","shell.execute_reply":"2021-12-17T05:45:01.490056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Build Recommender System**\n\n* Based on the analysis and visualizations, it’s clear that similar genres tend to have data points that are located close to each other while similar types of songs are also clustered together.\n* This observation makes perfect sense. Similar genres will sound similar and will come from similar time periods while the same can be said for songs within those genres. We can use this idea to build a recommendation system by taking the data points of the songs a user has listened to and recommending songs corresponding to nearby data points.\n* [Spotipy](https://spotipy.readthedocs.io/en/2.16.1/) is a Python client for the Spotify Web API that makes it easy for developers to fetch data and query Spotify’s catalog for songs. You have to install using `pip install spotipy`\n* After installing Spotipy, you will need to create an app on the [Spotify Developer’s page](https://developer.spotify.com/) and save your Client ID and secret key.","metadata":{}},{"cell_type":"code","source":"!pip install spotipy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nfrom collections import defaultdict\n\nsp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=os.environ[\"SPOTIFY_CLIENT_ID\"],\n                                                           client_secret=os.environ[\"SPOTIFY_CLIENT_SECRET\"]))\n\ndef find_song(name, year):\n    song_data = defaultdict()\n    results = sp.search(q= 'track: {} year: {}'.format(name,year), limit=1)\n    if results['tracks']['items'] == []:\n        return None\n\n    results = results['tracks']['items'][0]\n    track_id = results['id']\n    audio_features = sp.audio_features(track_id)[0]\n\n    song_data['name'] = [name]\n    song_data['year'] = [year]\n    song_data['explicit'] = [int(results['explicit'])]\n    song_data['duration_ms'] = [results['duration_ms']]\n    song_data['popularity'] = [results['popularity']]\n\n    for key, value in audio_features.items():\n        song_data[key] = value\n\n    return pd.DataFrame(song_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nfrom sklearn.metrics import euclidean_distances\nfrom scipy.spatial.distance import cdist\nimport difflib\n\nnumber_cols = ['valence', 'year', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']\n\n\ndef get_song_data(song, spotify_data):\n    \n    try:\n        song_data = spotify_data[(spotify_data['name'] == song['name']) \n                                & (spotify_data['year'] == song['year'])].iloc[0]\n        return song_data\n    \n    except IndexError:\n        return find_song(song['name'], song['year'])\n        \n\ndef get_mean_vector(song_list, spotify_data):\n    \n    song_vectors = []\n    \n    for song in song_list:\n        song_data = get_song_data(song, spotify_data)\n        if song_data is None:\n            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n            continue\n        song_vector = song_data[number_cols].values\n        song_vectors.append(song_vector)  \n    \n    song_matrix = np.array(list(song_vectors))\n    return np.mean(song_matrix, axis=0)\n\n\ndef flatten_dict_list(dict_list):\n    \n    flattened_dict = defaultdict()\n    for key in dict_list[0].keys():\n        flattened_dict[key] = []\n    \n    for dictionary in dict_list:\n        for key, value in dictionary.items():\n            flattened_dict[key].append(value)\n            \n    return flattened_dict\n\n\ndef recommend_songs( song_list, spotify_data, n_songs=10):\n    \n    metadata_cols = ['name', 'year', 'artists']\n    song_dict = flatten_dict_list(song_list)\n    \n    song_center = get_mean_vector(song_list, spotify_data)\n    scaler = song_cluster_pipeline.steps[0][1]\n    scaled_data = scaler.transform(spotify_data[number_cols])\n    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n    index = list(np.argsort(distances)[:, :n_songs][0])\n    \n    rec_songs = spotify_data.iloc[index]\n    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n    return rec_songs[metadata_cols].to_dict(orient='records')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommend_songs([{'name': 'Come As You Are', 'year':1991},\n                {'name': 'Smells Like Teen Spirit', 'year': 1991},\n                {'name': 'Lithium', 'year': 1992},\n                {'name': 'All Apologies', 'year': 1993},\n                {'name': 'Stay Away', 'year': 1993}],  data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This last cell will gives you a recommendation list of songs like this,\n\n\n```\n[{'name': 'Life is a Highway - From \"Cars\"',\n  'year': 2009,\n  'artists': \"['Rascal Flatts']\"},\n {'name': 'Of Wolf And Man', 'year': 1991, 'artists': \"['Metallica']\"},\n {'name': 'Somebody Like You', 'year': 2002, 'artists': \"['Keith Urban']\"},\n {'name': 'Kayleigh', 'year': 1992, 'artists': \"['Marillion']\"},\n {'name': 'Little Secrets', 'year': 2009, 'artists': \"['Passion Pit']\"},\n {'name': 'No Excuses', 'year': 1994, 'artists': \"['Alice In Chains']\"},\n {'name': 'Corazón Mágico', 'year': 1995, 'artists': \"['Los Fugitivos']\"},\n {'name': 'If Today Was Your Last Day',\n  'year': 2008,\n  'artists': \"['Nickelback']\"},\n {'name': \"Let's Get Rocked\", 'year': 1992, 'artists': \"['Def Leppard']\"},\n {'name': \"Breakfast At Tiffany's\",\n  'year': 1995,\n  'artists': \"['Deep Blue Something']\"}]\n```\n\n\n\n* You can change the given songs list as per your choice.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}